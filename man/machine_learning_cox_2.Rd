% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ML_pack.R
\name{machine_learning_cox_2}
\alias{machine_learning_cox_2}
\title{Machine Learning Pipeline for Cox Proportional Hazards Model (Alternative Version)}
\usage{
machine_learning_cox_2(
  data,
  seed = 123,
  train_percent = 0.7,
  n_round = 20,
  stratify = F,
  lambda_type = "lambda.min",
  bestcut = F,
  topn = 10
)
}
\arguments{
\item{data}{A dataframe where the first two columns are survival time and status.}

\item{seed}{Random seed for reproducibility (default: 123)}

\item{train_percent}{Proportion of data to use for training (default: 0.7)}

\item{n_round}{Number of bootstrap rounds for feature selection (default: 20)}

\item{stratify}{Logical indicating whether to use stratified sampling (default: FALSE)}

\item{lambda_type}{Regularization criterion for cv.glmnet: "lambda.min" (default) or "lambda.1se"}

\item{bestcut}{Logical indicating whether to determine optimal cutoff for risk groups (default: FALSE)}

\item{topn}{Number of top features to retain in feature selection (default: 10)}
}
\value{
A list containing:
\itemize{
  \item Training set results with risk scores and groups
  \item Testing set results with risk scores and groups
}
}
\description{
An alternative implementation of the survival analysis pipeline using Cox proportional hazards model with Elastic Net regularization.
This version performs feature selection before data splitting, which may be more suitable for certain datasets.
}
\details{
Key differences from machine_learning_cox:
1. Performs feature selection on the entire dataset before splitting
2. Scales data before feature selection
3. May be more appropriate for smaller datasets

The function performs the following steps:
1. Data scaling and feature selection
2. Data splitting
3. Model training with Elastic Net regularization
4. Risk score calculation and optimal cutoff determination
5. Survival curve visualization and PDF export
}
\examples{
\dontrun{
data <- data.frame(time = rnorm(100), status = rbinom(100, 1, 0.5),
                  matrix(rnorm(100*20), ncol=20))
results <- machine_learning_cox_2(data, train_percent = 0.8, topn = 5)
}

}
